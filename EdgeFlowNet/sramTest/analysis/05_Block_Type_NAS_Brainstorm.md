# 5. NAS 骨干块搜索策略（头脑风暴）

> 返回 [目录](00_README.md)
>
> ⚠️ **注意**: 本章为中间过渡方案，已被 [06_Final_NAS_Strategy.md](06_Final_NAS_Strategy.md) 全面修订。
> 保留本章供参考分析过程。

---

## 9.1 核心设计思路

Head 的 kernel size 搜索（7×7 / 5×5 / 3×3）用小卷积换取高 FPS，但**一定会损失精度**。

骨干块搜索的目标是反向补偿：**用更高效的块设计节省 Cycle 的同时，保持甚至提升特征质量**。

两种互补策略：

1. **更优的块设计**: 找到「精度/Cycle 比率」优于 ResBlock 的块
2. **非对称搜索**: 编码器用精度优先块，解码器用速度优先块，将省下的 Cycle 预算「反哺」编码器容量

---

## 9.2 精确 Cycle 预算分析（192×256, per-layer 数据）

### 四个骨干位置的 Cycle 拆解

| 位置 | 分辨率 | 通道 | ResBlock | ShuffleNet | MBConv_E4 | MBConv_E6 |
|------|--------|------|---------|------------|-----------|-----------|
| **enc_0** | 48×64 | 64ch | 4.40M | 0.75M | 3.25M | 5.89M |
| **enc_1** | 24×32 | 128ch | 4.21M | 0.50M | 2.59M | 3.69M |
| **dec_0** | 12×16 | 256ch | 9.72M | 0.56M | 4.87M | 7.24M |
| **dec_1** | 24×32 | 128ch | 4.17M | 0.50M | 2.59M | 3.69M |
| **骨干合计** | | | **22.50M** | **2.32M** | **13.30M** | **20.51M** |
| vs ResBlock | | | 基线 | **-90%** | **-41%** | -9% |

### 整体 Cycle 预算

| 组件 | Cycles | 占比 | 说明 |
|------|--------|------|------|
| Stem (7×7 + 5×5) | 5.19M | 9.6% | 固定不变 |
| **4 个骨干块** | **22.50M** | **41.6%** | ← NAS 搜索目标 |
| Stride Conv (2 个) | 3.03M | 5.6% | 固定不变 |
| Decoder Upsample (2 个) | 8.42M | 15.6% | 固定 Bilinear+Conv3×3 |
| **5 个 Head 层** | **11.52M** | **21.3%** | ← Head NAS 搜索目标 |
| AccumPreds | 3.41M | 6.3% | 固定 (Resize+Add) |
| **总计** | **~54.07M** | **100%** | ResBlock 基线 |

> **关键发现**: dec_0 (ResBlock, 256ch, 12×16) 独占 **9.72M cycles (18%)**，但 NPU 利用率仅 **36-37%**。
> 这是单个最大瓶颈点，替换为 ShuffleNet 仅需 0.56M → **节省 9.16M cycles**。

---

## 9.3 各位置在光流估计中的角色

### 编码器 (enc_0, enc_1) —— 精度关键

编码器从双帧拼接输入（6ch → H×W×6）构建特征金字塔，这些特征是光流匹配的基础。

| 位置 | 分辨率 | 功能 | 特征要求 |
|------|--------|------|---------|
| enc_0 | H/4, 64ch | 低级特征：边缘、纹理、梯度方向 | 判别性强，空间精确 |
| enc_1 | H/8, 128ch | 中级特征：结构、纹理组合、局部上下文 | 通道多样性高 |

**光流对编码器特征的核心要求**:

1. **判别性**: 相似纹理区域的特征必须可区分（例如墙面砖块） → 需要**密集通道交互**
2. **鲁棒性**: 特征需对光照变化不敏感 → 需要**足够的通道多样性**
3. **空间精度**: 特征需精确定位到像素 → 需要**足够的空间处理能力**

> ⚠️ **编码器特征质量直接影响全部三个 Head 的输出。弱编码器 → 三个 Head 都变差。**
> 所有已发表的光流网络（FlowNet, PWC-Net, RAFT, LiteFlowNet）均在编码器使用密集卷积。

### 解码器 (dec_0, dec_1) —— 速度优先

| 位置 | 分辨率 | 功能 | 特征要求 |
|------|--------|------|---------|
| dec_0 | H/16, 256ch | 在最低分辨率解码潜在表示 | 通道聚合 |
| dec_1 | H/8, 128ch | 细化解码特征，为 Head 提供输入 | 空间细化 |

**解码器可以更轻量的原因**:

1. 多尺度 Head 在每个分辨率提供**直接监督** → 减轻解码器的重建压力
2. dec_0 在极低分辨率 (12×16) 运行 → ResBlock 的 NPU 利用率仅 **36%**，效率极低
3. 解码器是**特征精炼**，不是从头构建特征 → 精度敏感度低于编码器

---

## 9.4 推荐的 Block Choice 选项

### 已有选项（NPU 兼容性已验证 ✅）

| # | Block | 结构 | MAC/pixel | vs ResBlock | 通道交互强度 | NPU 特性 |
|---|-------|------|-----------|-------------|------------|---------|
| 1 | **ResBlock** | 2×Conv3×3 + Add | 18C² | 基线 | ⭐⭐⭐ 密集 (全通道×2) | 利用率 36-93% |
| 2 | **ShuffleNetV2** | Split+DW+PW+Concat+Shuffle | ~2C² | **-90%** | ⭐ 弱 (半通道) | 极快 |
| 3 | **MBConv_E4** | 1×1→DW3×3→1×1 (E=4) | ~10C² | -41% | ⭐⭐ 中 (1×1 密集) | DW 利用率 5-9% |

### 新增选项（全部使用标准 Conv/DW 算子，NPU 理论兼容，需 Benchmark 验证）

| # | Block | 结构 | MAC/pixel | 预估节省 | 通道交互强度 | 核心优势 |
|---|-------|------|-----------|---------|------------|---------|
| 4 | **MBConv_E2** | 1×1→DW3×3→1×1 (E=2) | ~6C² | ~-55% | ⭐⭐ 中 | 比 E4 快，无 SRAM 溢出风险 |
| 5 | **FusedMBConv** | Conv3×3(C→C)+Conv1×1(C→C)+Add | 10C² | ~-35% | ⭐⭐⭐ **密集** | 无 DW！全部高利用率算子 |

### 各选项详解

**选项 4: MBConv_E2（低扩展比倒残差块）**

```
输入 C → [1×1 扩展 C→2C] → [DW 3×3 保持 2C] → [1×1 投影 2C→C] → Add → 输出 C
```

- 与 MBConv_E4 完全相同的结构，仅扩展比从 4 降到 2
- enc_0: DW 中间通道 = 128ch，张量 = 128×48×64 = **393KB** ✅（vs E4 的 256ch = 768KB）
- 解决了 E4/E6 在较高分辨率位置的 SRAM 溢出风险
- **适用场景**: enc_1, dec_0, dec_1（需要一定通道交互但对速度敏感的位置）

**选项 5: FusedMBConv（融合倒残差块，EfficientNetV2 风格）** ⭐ 重点推荐

```
输入 C → [Conv 3×3: C→C] → BN → ReLU → [Conv 1×1: C→C] → BN → Add → ReLU → 输出 C
```

| 对比维度 | ResBlock | FusedMBConv | MBConv_E4 |
|---------|---------|-------------|-----------|
| 空间卷积 | 2× Conv3×3 (密集) | 1× Conv3×3 (密集) | 1× DW3×3 (逐通道) |
| 通道混合 | 2× 全通道交互 | 1× 全通道 + 1× 1×1精炼 | 2× 1×1 交互 |
| MAC/pixel | 18C² | 10C² | ~10C² |
| NPU 利用率 | 中-高 (36-93%) | **中-高 + 极高** | 高 + **极低**(DW 5-9%) |
| DW 算子 | 无 | **无** ✅ | 有 ❌ |

**FusedMBConv 的核心优势**:

1. **完全没有 DW Conv** → 无 5-9% 低利用率算子，所有算子都是 NPU 高效的标准 Conv
2. **3×3 Conv 提供密集通道+空间交互**（与 ResBlock 同级，远强于 MBConv 的 DW）
3. **1×1 Conv 提供额外通道精炼**（NPU 利用率 90-100%，额外开销极小）
4. **EfficientNetV2 论文实验证明**: 在网络早期阶段，FusedMBConv 同时优于 MBConv 的**速度和精度**

**预估 enc_0 Cycle 对比**:

| Block | Conv3×3 | Conv1×1/Conv3×3 | Add | 总计 | vs ResBlock |
|-------|---------|-----------------|-----|------|-------------|
| ResBlock | 1.90M | 1.90M | 0.59M | **4.40M** | 基线 |
| **FusedMBConv** | 1.90M | **~0.20M** | 0.59M | **~2.69M** | **-39%** |
| MBConv_E4 | 0.73M(1×1)+1.14M(DW) | 0.79M(1×1) | 0.59M | 3.25M | -26% |
| ShuffleNet | — | — | — | 0.75M | -83% |

> **FusedMBConv 在保持密集通道交互（精度）的同时，Cycle 减少 ~39%（速度），是编码器位置的最佳候选。**

---

## 9.5 非对称位置搜索策略

### 核心理念

允许每个位置独立选择不同的 Block 类型，而非全网统一。

| 位置 | 推荐搜索范围 | 搜索理由 |
|------|-------------|---------|
| **enc_0** | ResBlock, FusedMBConv | 特征构建起点，精度**最**敏感，必须密集通道交互 |
| **enc_1** | ResBlock, FusedMBConv, MBConv_E2 | 中级特征，可适度轻量化 |
| **dec_0** | ShuffleNet, MBConv_E2, FusedMBConv | 最低分辨率，ResBlock NPU 效率极低 (36%)，最大节省点 |
| **dec_1** | ShuffleNet, MBConv_E2, FusedMBConv | 中等分辨率，速度敏感 |

> 编码器**不推荐** ShuffleNet 和 MBConv，因为：
> - ShuffleNet 只处理**一半通道**，光流特征的判别性可能严重不足
> - MBConv 的 DW Conv **无跨通道交互**，无法构建通道间的关联特征
> - 所有已发表的光流网络编码器均使用密集卷积（标准 Conv）

### 预估组合效果 (192×256)

| 配置 | enc_0 | enc_1 | dec_0 | dec_1 | 骨干 Cycles | 总 Cycles | FPS 估计 |
|------|-------|-------|-------|-------|-----------|----------|---------|
| 全 ResBlock (基线) | 4.40M | 4.21M | 9.72M | 4.17M | 22.50M | ~54.1M | 7.40 |
| 全 ShuffleNet | 0.75M | 0.50M | 0.56M | 0.50M | 2.32M | ~33.9M | 11.78 |
| **ResBlock enc + Shuffle dec** | 4.40M | 4.21M | 0.56M | 0.50M | **9.67M** | ~41.2M | **~9.7** |
| **FusedMBConv enc + Shuffle dec** | 2.69M | 2.50M | 0.56M | 0.50M | **6.25M** | ~37.8M | **~10.6** |
| FusedMBConv all | 2.69M | 2.50M | 1.85M | 2.50M | 9.54M | ~41.1M | ~9.7 |

> **最佳推荐: FusedMBConv 编码器 + ShuffleNet 解码器**
> - 编码器保持密集通道交互 (精度保障)
> - 解码器大幅提速 (Cycle 预算释放)
> - 预估 FPS ~10.6（比全 ResBlock 快 **43%**，比全 ShuffleNet 慢 **10%**，但编码器强很多）

---

## 9.6 额外搜索维度：用速度预算换取更强容量

骨干轻量化节省的 Cycle 可以「再投资」到更强的网络容量中，**实现速度和精度的双赢**。

### 维度 1: 通道宽度 (InitNeurons)

| InitNeurons | 通道序列 | 骨干 Cycle (估, ShuffleNet) | FPS 估计 | 特征容量 |
|------------|---------|---------------------------|---------|---------|
| 24 | 24→48→96→192 | ~1.3M | ~12.5 | -25% |
| **32** (当前) | 32→64→128→256 | 2.32M | 11.78 | 基线 |
| **48** | 48→96→192→384 | ~5.2M | ~10.5 | **+50%** |
| 64 | 64→128→256→512 | ~9.3M | ~9.0 | +100% |

**关键洞察**: ShuffleNet(48ch) 的骨干 Cycle (~5.2M) 仍远低于 ResBlock(32ch) 的 22.50M。
→ **ShuffleNet + 50% 更宽的通道，速度仍快 42%，但特征容量多 50%**。

对于光流估计，更多通道意味着：
- 更丰富的边缘/纹理特征表示
- 更强的判别能力（区分相似纹理区域）
- 更好的亚像素精度

### 维度 2: 子块数量 (NumSubBlocks)

| NumSubBlocks | Encoder/Decoder 块数 | 网络总深度 | 感受野 |
|-------------|---------------------|-----------|-------|
| **2** (当前) | 2 enc + 2 dec = 4 | ~12 层 | 基线 |
| **3** | 3 enc + 3 dec = 6 | ~18 层 | **+50%** |

轻量块允许堆叠更多子块而不超预算：

```
ResBlock × 2 blocks:  22.50M cycles, 4 blocks,  ~8 effective convolutions
ShuffleNet × 3 blocks: ~3.5M cycles, 6 blocks, ~12 effective convolutions
                        ↑ 更快       ↑ 更深    ↑ 更多特征变换层次
```

> **更深的网络通常有更好的特征提取能力**, 特别是对于需要多层次抽象的光流估计。

### 维度 3: Encoder/Decoder 深度非对称

- Encoder 3 blocks + Decoder 2 blocks: 更强的特征编码能力
- Encoder 2 blocks + Decoder 3 blocks: 更精细的特征恢复

---

## 9.7 光流估计的特殊考量

以下是对光流任务的分析，指导 Block 选择策略:

| 光流需求 | 影响的网络组件 | Block 设计要求 |
|---------|-------------|--------------|
| **大位移处理** | Encoder 感受野 | 更深的 Encoder（更多 sub-blocks）或更大 kernel |
| **亚像素精度** | Encoder 特征分辨率 | 保持足够的空间分辨率 + 通道数 |
| **遮挡处理** | Decoder 上下文聚合 | Decoder 需一定的通道交互能力 |
| **纹理区域匹配** | Encoder 通道多样性 | 密集通道交互（Conv > DW）|
| **运动边界锐利** | Head predict 卷积 | 大 kernel 有助于边界保持 (7×7) |
| **光照不变性** | Encoder 特征鲁棒性 | BN + 足够深度的特征变换 |

**核心原则**:
- 编码器特征质量是所有下游输出的基础 → **不可在编码器上过度节省**
- 解码器+Head 共同决定输出质量 → **解码器可以适度轻量化**
- 通道宽度和深度的增加能直接提升特征表达力 → **用速度预算换容量是可行的**

---

## 9.8 完整 NAS 搜索空间汇总

### Head 搜索维度（已确定）

| 位置 | 选项 | 组合数 |
|------|------|--------|
| Head0 output | Conv7×7, Conv5×5, Conv3×3 | 3 |
| Head1 upsample | Conv5×5, Conv3×3 | 2 |
| Head1 output | Conv7×7, Conv5×5, Conv3×3 | 3 |
| Head2 upsample | Conv7×7, Conv5×5, Conv3×3 | 3 |
| Head2 output | Conv7×7, Conv5×5, Conv3×3 | 3 |
| **Head 小计** | | **162** |

### 骨干搜索维度（本次讨论）

| 位置 | 选项 | 组合数 |
|------|------|--------|
| enc_0 | ResBlock, FusedMBConv | 2 |
| enc_1 | ResBlock, FusedMBConv, MBConv_E2 | 3 |
| dec_0 | ShuffleNet, MBConv_E2, FusedMBConv | 3 |
| dec_1 | ShuffleNet, MBConv_E2, FusedMBConv | 3 |
| **骨干小计** | | **54** |

### 超参数搜索维度

| 参数 | 选项 | 组合数 |
|------|------|--------|
| InitNeurons | 32, 48 | 2 |
| NumSubBlocks | 2, 3 | 2 |
| **超参数小计** | | **4** |

### 总搜索空间

**162 (Head) × 54 (骨干) × 4 (超参数) = 34,992 种组合**

> 建议采用**分层搜索**或**随机采样**策略，而非穷举：
>
> 1. **第一阶段**: 固定 Head 为 Conv3×3（最快），搜索骨干+超参数（54×4=216 种），找到最佳骨干配置
> 2. **第二阶段**: 固定最佳骨干，搜索 Head（162 种），找到最佳精度-速度权衡
> 3. **第三阶段**: 联合微调 Top-10 配置

---

## 9.9 实施优先级建议

| 优先级 | 任务 | 预期收益 | 工作量 |
|--------|------|---------|-------|
| 🥇 P0 | 实现 FusedMBConv + NPU 验证 | 编码器 -39% cycle，保持精度 | 中 |
| 🥇 P0 | 实现 enc/dec 独立 Block 选择 | 非对称搜索，释放 cycle 预算 | 中 |
| 🥈 P1 | 实现 MBConv_E2 + NPU 验证 | 填补 MBConv_E4 和 ShuffleNet 之间的空白 | 低 |
| 🥈 P1 | 实现 InitNeurons 搜索 (32/48) | 通道宽度对精度影响可能大于 Block 类型 | 低 |
| 🥉 P2 | 实现 NumSubBlocks 搜索 (2/3) | 更深网络，但需要重新设计 Head 连接 | 高 |
| 🥉 P2 | 完整 NAS 训练验证 | 最终精度只能通过训练确定 | 极高 |

> **特别说明**: 以上所有 Cycle 分析基于 NPU Benchmark，只能预测**速度**。
> **精度**必须通过实际训练和光流评估（EPE, Fl-all）来验证。
> NAS 的正确流程是：先找到 Pareto 最优的速度配置集合，再训练 Top-N 候选验证精度。

