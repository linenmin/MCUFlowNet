#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• ONNX æ¨¡å‹æ¨ç†æ˜¯å¦æ­£å¸¸å·¥ä½œ
ç¡®è®¤æ¨¡å‹ç»“æ„æ­£ç¡®ï¼Œæ‰€æœ‰å±‚çš„è¾“å‡ºå½¢çŠ¶åŒ¹é…
"""

import numpy as np

try:
    import onnxruntime as ort
    import onnx
except ImportError:
    print("è¯·å…ˆå®‰è£…: pip install onnxruntime onnx")
    exit(1)


def check_all_node_shapes(model_path):
    """æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çš„è¾“å‡ºå½¢çŠ¶ï¼Œæ‰¾å‡ºå°ºå¯¸é—®é¢˜"""
    print("\n" + "=" * 60)
    print("[è¯¦ç»†å½¢çŠ¶æ£€æŸ¥] æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çš„è¾“å‡ºå½¢çŠ¶")
    print("=" * 60)
    
    model = onnx.load(model_path)
    
    # è¿è¡Œå½¢çŠ¶æ¨æ–­
    try:
        model = onnx.shape_inference.infer_shapes(model)
    except Exception as e:
        print(f"  å½¢çŠ¶æ¨æ–­å¤±è´¥: {e}")
        return
    
    # æ”¶é›†æ‰€æœ‰å€¼ä¿¡æ¯
    value_info = {}
    for vi in model.graph.value_info:
        shape = []
        for dim in vi.type.tensor_type.shape.dim:
            if dim.dim_value:
                shape.append(dim.dim_value)
            else:
                shape.append(dim.dim_param or "?")
        value_info[vi.name] = shape
    
    # æ·»åŠ è¾“å…¥è¾“å‡º
    for inp in model.graph.input:
        shape = []
        for dim in inp.type.tensor_type.shape.dim:
            shape.append(dim.dim_value if dim.dim_value else "?")
        value_info[inp.name] = shape
    
    for out in model.graph.output:
        shape = []
        for dim in out.type.tensor_type.shape.dim:
            shape.append(dim.dim_value if dim.dim_value else "?")
        value_info[out.name] = shape
    
    # æŸ¥æ‰¾é—®é¢˜èŠ‚ç‚¹ (åŒ…å« 516 æˆ–å…¶ä»–éé¢„æœŸå°ºå¯¸)
    print("\n[å¯ç–‘å°ºå¯¸èŠ‚ç‚¹] (åŒ…å« 516, 258, 129 ç­‰é 2 çš„å¹‚æ¬¡å°ºå¯¸)")
    suspicious = []
    for name, shape in value_info.items():
        for dim in shape:
            if isinstance(dim, int) and dim > 1:
                # æ£€æŸ¥æ˜¯å¦æ˜¯éé¢„æœŸå°ºå¯¸ (ä¸æ˜¯ 512, 256, 128, 64, 32, 576, 1024 ç­‰)
                expected = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 576, 288, 144, 72, 36, 18]
                if dim not in expected:
                    suspicious.append((name, shape, dim))
                    break
    
    if suspicious:
        for name, shape, bad_dim in suspicious[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            print(f"  âš ï¸  {name}: {shape} (é—®é¢˜å°ºå¯¸: {bad_dim})")
    else:
        print("  âœ… æœªå‘ç°å¯ç–‘å°ºå¯¸")
    
    # ç»Ÿè®¡ Resize å’Œ ConvTranspose èŠ‚ç‚¹
    print("\n[Resize/ConvTranspose èŠ‚ç‚¹ç»Ÿè®¡]")
    resize_count = 0
    convtrans_count = 0
    for node in model.graph.node:
        if node.op_type == "Resize":
            resize_count += 1
            out_shape = value_info.get(node.output[0], "æœªçŸ¥")
            print(f"  Resize: {node.name} -> {out_shape}")
        elif node.op_type == "ConvTranspose":
            convtrans_count += 1
            out_shape = value_info.get(node.output[0], "æœªçŸ¥")
            print(f"  ConvTranspose: {node.name} -> {out_shape}")
    
    print(f"\n  æ€»è®¡: {resize_count} Resize, {convtrans_count} ConvTranspose")


def test_inference(model_path, input_shape=(1, 576, 1024, 6)):
    """æµ‹è¯• ONNX æ¨¡å‹æ¨ç†"""
    print("=" * 60)
    print(f"æµ‹è¯•æ¨¡å‹: {model_path}")
    print(f"è¾“å…¥å½¢çŠ¶: {input_shape}")
    print("=" * 60)
    
    # åˆ›å»ºæ¨ç†ä¼šè¯
    try:
        sess = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
    input_info = sess.get_inputs()[0]
    output_info = sess.get_outputs()[0]
    
    print(f"\n[è¾“å…¥ä¿¡æ¯]")
    print(f"  åç§°: {input_info.name}")
    print(f"  å½¢çŠ¶: {input_info.shape}")
    print(f"  ç±»å‹: {input_info.type}")
    
    print(f"\n[è¾“å‡ºä¿¡æ¯]")
    print(f"  åç§°: {output_info.name}")
    print(f"  å½¢çŠ¶: {output_info.shape}")
    print(f"  ç±»å‹: {output_info.type}")
    
    # åˆ›å»ºéšæœºè¾“å…¥
    input_data = np.random.randn(*input_shape).astype(np.float32)
    
    # è¿è¡Œæ¨ç†
    print(f"\n[æ¨ç†æµ‹è¯•]")
    try:
        outputs = sess.run(None, {input_info.name: input_data})
        output = outputs[0]
        print(f"  âœ… æ¨ç†æˆåŠŸ!")
        print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  è¾“å‡ºèŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
        return True
    except Exception as e:
        print(f"  âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
    else:
        model_path = "edgeflownet_576_1024.onnx"
    
    # å…ˆæ£€æŸ¥è¯¦ç»†å½¢çŠ¶
    check_all_node_shapes(model_path)
    
    # å†æµ‹è¯•æ¨ç†
    success = test_inference(model_path)
    print()
    if success:
        print("ğŸ‰ æ¨¡å‹æ¨ç†æµ‹è¯•é€šè¿‡!")
    else:
        print("â›” æ¨¡å‹æ¨ç†æµ‹è¯•å¤±è´¥!")

